{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Intro-Computational-Graphs.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPFMBs5th081QnopK/xCCkg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/datasith/ML-Notebooks-TensorFlow/blob/main/Intro_Computational_Graphs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Introduction to Computational Graphs with TensorFlow\n",
        "\n",
        "by [Cisco Zabala | @datasith](https://linkedin.com/in/datasith)\n",
        "\n",
        "\n",
        "In this notebook I provide a short introduction and overview of computational graphs using TensorFlow inspired by the PyTorch equivalent written by [Elvis Saravia](https://github.com/dair-ai/ML-Notebooks) et al.\n",
        "\n",
        "There are several materials online that cover theory on the topic of computational graphs. However, it seems much easier to learn the concept using code, thus this is an attempt to bridge the gap that should be particularly useful for those on getting started with the subject.  \n",
        "\n",
        "Inspired by Olah's article [\"Calculus on Computational Graphs: Backpropagation\"](https://colah.github.io/posts/2015-08-Backprop/), Elvis put together a few code snippets to get you started with computationsl graphs with PyTorch. Similarly, this TensorFlow companion notebook should complement that article, which you are encouraged to reference for more comprehensive explanations."
      ],
      "metadata": {
        "id": "xyDfyGqj9uu5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Why Computational Graphs?"
      ],
      "metadata": {
        "id": "38ioPmY2-8i8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "When talking about neural networks in any context, [backpropagation](https://en.wikipedia.org/wiki/Backpropagation) is an important topic to understand because it is the algorithm used for training deep neural networks. \n",
        "\n",
        "Backpropagation is used to calculate derivatives which is what you need to keep optimizing parameters of the model and allowing the model to learn on the task at hand. \n",
        "\n",
        "Many of the deep learning frameworks today like PyTorch does the backpropagation out-of-the-box using [**automatic differentiation**](https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html). \n",
        "\n",
        "To better understand how this is done it's important to talk about **computational graphs** which defines the flow of computations that are carried out throughout the network. Along the way we will use `tf.GradientTape` to demonstrate in code how this works. "
      ],
      "metadata": {
        "id": "eOJA92kK-7wc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hw4sYNoc7wjq"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = tf.Variable([2.])\n",
        "b = tf.Variable([1.])"
      ],
      "metadata": {
        "id": "o5tgbfe0715T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with tf.GradientTape(persistent=True) as tape:\n",
        "    c = a + b\n",
        "    d = b + 1\n",
        "    e = c * d\n",
        "\n",
        "de_da = tape.gradient(e, a)\n",
        "de_db = tape.gradient(e, b)    "
      ],
      "metadata": {
        "id": "_s-D21al8A-u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "de_da"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pB6TqXC08G7J",
        "outputId": "84a73d2d-d44c-4289-8604-e66718f41720"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1,), dtype=float32, numpy=array([2.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "de_db"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "omPJuSUG8h0Y",
        "outputId": "84dff01e-cdbc-44a7-9842-834502a2572b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1,), dtype=float32, numpy=array([5.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "MxCPd-Ax8kgW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}